# メッセージに対応してストリームを処理するサーバーレス関数をデプロイする

### イベント・ストリームのレコードを OpenWhisk で分析する

English version: https://developer.ibm.com/patterns/serverless-event-stream-processing
ソースコード: https://github.com/IBM/ibm-cloud-functions-refarch-data-processing-message-hub

###### 最新の英語版コンテンツは上記URLを参照してください。
last_updated: 2018-12-13

 
## 概要

最近のクラウド・ネイティブ・アプリケーションの多くでは、膨大な量のデータが生成され、このデータを使用して、高度に分散された複数のサービスをリンクしています。大量のメッセージをストリーミングするシステムとしては Apache Kafka を使用できますが、受信側のシステムも、こうしたメッセージを処理して個々のレコードを操作できるようでなければなりません。

OpenWhisk をベースに構築されたイベント駆動型アーキテクチャーを使用すると、データを処理したり、分散アーキテクチャー内の他のシステムにデータを送信したりするために、キューから送られてくるメッセージに対応してロジックを実行する関数を作成できます。しかも、料金が発生するのは、実行時間が 1 秒にも満たない分析関数で使用するリソースに対してのみです。この手法により、処理するトランザクションの数と使用するクラウド・リソースの量を正しく釣り合わせることができます。

このような手法は、膨大な量のストリーム・ベースのメッセージ処理をサポートするような新しいクラウド・ネイティブのアプリケーションに対してイベント駆動型のサーバーレス・アーキテクチャーを保証するものです。この手法に従うことで、ボリュームに見合うだけの十分な数のサーバーを用意するかどうか懸念することなく、膨大なメッセージの処理を開始できます。

## 説明

このコード・パターンでは、Cloud Functions を使用してメッセージに対応してコードを実行したり、データ・レコードのストリームを処理したりする場合のリファレンス・アーキテクチャーをデプロイする方法をサンプル・コードによって説明します。このアーキテクチャーでは、(Apache Kafka を利用した) Event Streams サービスからメッセージが到着するまで、コードは一切実行されません。メッセージが到着した時点で Cloud Functions インスタンスが起動され、その後はメッセージのストリームを処理するために必要な数に応じてインスタンスが自動的にスケーリングします。

このリファレンス・アーキテクチャーをデプロイするには、Cloud Functions ユーザー・インターフェースを使用することも、使用しているシステム上にインストールされたコマンド・ライン・ツールを使用することもできます。

IBM Cloud アカウントをまだ登録していない場合は、アカウントを登録して [Cloud Functions ダッシュボード](https://cloud.ibm.com/openwhisk?cm_sp=ibmdev-_-developer-patterns-_-cloudreg)を表示してください。このダッシュボードで、必要に応じて他の[リファレンス・アーキテクチャーのテンプレート](https://github.com/topics/ibm-cloud-functions-refarch)を調べたりコマンド・ライン・ツールをダウンロードしたりできます。

このコード・パターンでは、次のコンポーネントを使用します。

* [IBM Cloud Functions](https://cloud.ibm.com/openwhisk?cm_sp=ibmdev-_-developer-patterns-_-cloudreg) (Apache OpenWhisk を採用)
* [IBM Event Streams](https://cloud.ibm.com/catalog/services/event-streams?cm_sp=ibmdev-_-developer-patterns-_-cloudreg) (Apache Kafka を採用)

デモ・アプリケーションでは、(Apache Kafka ベースの) IBM Event Streams に対してメッセージの読み取り/:書き込みを行う (Apache OpenWhisk ベースの) IBM Cloud Functions インスタンスを 2 つデプロイして、データ・サービスと連動し、メッセージ・イベントに対応してロジックを実行する方法を説明します。

一方の Functions インスタンス (アクション) は、1 つ以上のデータ・レコードからなるメッセージ・ストリームによってトリガーされます。これらのレコードはシーケンス (宣言型でアクションを連鎖させるための手段) 内で、もう一方のアクションに接続されます。この 2 番目のアクションは、メッセージを集約し、その変換後の要約メッセージを別のトピックに送信します。

このコード・パターンを完了すると、以下のスキルを習得できます。

* サーバーレス・コンピューティング:  メッセージに対応してコードを実行する、Cloud Functions を使用したリファレンス・アーキテクチャーをデプロイする
* Kafka: データ・サービスと連動し、メッセージ・イベントに対応してロジックを実行する

## フロー

![フロー](../../images/serverless-event-stream-architecture.png)

1. 開発者がアプリケーションを公開するクライアントをシミュレートして、新しい JSON オブジェクトの配列を Apache Kafka のトピックに追加します。
1. このトピックに送信されるメッセージを listen するトリガーが、メッセージの送信に対応してイベントを起動します。
1. このトリガーは、ルールによって最初のアクションにマッピングされています。最初のアクションは、メッセージ配列をダウンロードして解析することです。
1. メッセージ配列がシーケンス内のもう一方のアクションに送信されます。この 2 番目のアクションにより、配列に含まれるデータが単一のメッセージに集約されます。
1. 2 番目のアクションが新しいメッセージを別の Event Streams キューに送信し、他のアプリケーションでこのメッセージを処理できるようにします。

## 手順

このコード・パターンの詳細な手順については、GitHub リポジトリー内に置かれている [README.md](https://github.com/IBM/ibm-cloud-functions-refarch-data-processing-message-hub/blob/master/README.md) ファイルを参照してください。手順の概要は以下のとおりです。

1. Cloud Functions コンソールのユーザー・インターフェースを使用してリファレンス・アーキテクチャーをデプロイします。
2. wskdeploy コマンド・ライン・ツールを使用してリファレンス・アーキテクチャーをデプロイします。
3. 代替デプロイ手法を使用します。
